---
description: Use when creating a new optimizer.
globs:
alwaysApply: false
---

## Optimizer Subclass Creation

When creating a new Optimizer:

### Structure Requirements:
- **Inherit from BaseOptimizer**: Use `BaseOptimizer` as the base class
- **Implement optimization algorithm**: Override key optimization methods
- **Handle gradient accumulation**: Work with the gradient accumulator system
- **Support momentum/adaptive learning**: Implement algorithm-specific features

### Template Pattern:
```swift
import Foundation
import NumSwift

/// [Description of the optimization algorithm]
public class [OptimizerName]: BaseOptimizer {
    
    // Algorithm-specific parameters
    private var [param1]: Tensor.Scalar
    private var [param2]: Tensor.Scalar
    
    // State variables for optimization
    private var [stateVar1]: [Tensor.Value] = []
    private var [stateVar2]: [Tensor.Value] = []
    
    public override var trainable: Trainable {
        didSet {
            build() // Rebuild state when trainable changes
        }
    }
    
    public init(_ trainable: Trainable,
                device: Device = CPU(),
                learningRate: Tensor.Scalar,
                batchSize: Int,
                [algorithmParams]) {
        
        // Set algorithm parameters
        self.[param1] = [param1]
        self.[param2] = [param2]
        
        super.init(trainable,
                   device: device,
                   learningRate: learningRate,
                   batchSize: batchSize)
        
        build()
    }
    
    // Build/rebuild optimizer state
    private func build() {
        // Initialize state variables based on trainable layers
        // Reset state arrays
        [stateVar1] = []
        [stateVar2] = []
        
        // Initialize for each layer
        for layer in trainable.layers where layer.trainable {
            // Initialize state for this layer
        }
    }
    
    // Core optimization step
    public override func apply(_ gradients: Tensor.Gradient) {
        // Implement algorithm-specific gradient application
        // Update state variables
        // Apply computed updates to layer weights
        
        super.apply(gradients) // Call parent for common functionality
    }
    
    // Reset optimizer state
    public override func reset() {
        super.reset()
        build() // Rebuild state
    }
}
```